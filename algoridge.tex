% !TeX spellcheck = en_US
\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{xstring}
\usepackage{catchfile}

% borrowed from https://tex.stackexchange.com/questions/455396/how-to-include-the-current-git-commit-id-and-branch-in-my-document#:~:text=the%20branch%20name%20can%20be%20extracted%20from%20.git/HEAD
\CatchFileDef{\headfull}{.git/HEAD}{}
\StrGobbleRight{\headfull}{1}[\head]
\StrBehind[2]{\head}{/}[\branch]
\IfFileExists{.git/refs/heads/\branch}{%
    \CatchFileDef{\commit}{.git/refs/heads/\branch}{}}{%
    \newcommand{\commit}{\dots~(in \emph{packed-refs})}}

\sloppy

\newcommand{\pd}[2]{\ensuremath{\frac{\partial #1}{\partial #2}}}
\newcommand{\cf}{\textit{cf.} }
\newcommand{\eg}{\textit{e.g.}, }
\DeclareMathOperator{\Tr}{Tr}

\author{Lev Melnikovsky}
%
\title{On the Ridge Detection Algorithm}
%\date{\texttt{\commit} on branch \texttt{\branch}}
\begin{document}
\maketitle
%\begin{abstract}
%\end{abstract}
%\section{Introduction}

Ridge detection algorithms are important in various applications~\cite{ridges94},\cite{ridges96}.

Local \textit{height definition} of the ridge for a smooth function $f(\mathbf{x})$, $\mathbf{x} \in \mathbb{R}^n$ is a set of points such that:
\begin{enumerate}
\item the gradient $\mathbf{v} = \nabla f$ is the eigenvector of the Hessian $\boldsymbol{H} = \partial^2 \! f/\partial x^i\, \partial x^j$, corresponding to the eigenvalue $\Lambda$;
\item all other eigenvalues $\lambda_\alpha$ are 
\begin{enumerate}
\item smaller $\lambda_\alpha < \Lambda$,
\item negative $\lambda_\alpha <0$.
\end{enumerate} 
\end{enumerate}

Present note suggests an optimization of the straightforward approach to explicitly test the gradient against the diagonalized Hessian and its spectrum.

Namely, it should be more efficient to test if the gradient $\mathbf{v}$ is indeed an eigenvector $\boldsymbol{H} \mathbf{v} = \Lambda\mathbf{v}$. This statement is equivalent to:
\begin{equation}
e^{j k \dots}
\frac{\partial^2 \! f}{\partial x^i\, \partial x^j}
\pd{f}{x^i}\pd{f}{x^k}
=0,
\end{equation}
where $e^{j k \dots}$ is the n-dimensional Levi-Civita symbol and the Einstein summation convention is adopted. This equation can be transformed as follows:
\begin{equation}
0=
e^{j k \dots}
\pd{v^i}{x^j} v^i v^k=
\frac{e^{j k \dots}}{2}
\pd{(v^i v^i)}{x^j}  v^k=
\frac{e^{j k \dots}}{2}
\pd{(\left|\mathbf{v}\right|^2 v^k)}{x^j},
\end{equation}
or
\begin{equation}
\label{curl}
0=
\mathrm{curl} \left(\left|\mathbf{v}\right|^2 \mathbf{v}\right),
\end{equation}
where $\mathrm{curl}$ is a scalar for 2-dimensional images and a vector for 3-dimensional fields. This ``sign-changing'' condition can be efficiently bi-sected.

The Hessian spectral analysis is only necessary where Eq.\eqref{curl} is satisfied. It can also be performed without computationally heavy explicit diagonalization. We begin with the eigenvalue $\Lambda$, corresponding to the eigenvector $\mathbf{v}$:
\begin{equation}
\Lambda = \frac{\mathbf{v}^T\boldsymbol{H} \mathbf{v}}{\left|\mathbf{v}\right|^2}.
\end{equation}

If $\Lambda$ turns out to be negative, then it remains to check whether the matrix 
\begin{equation}
\label{he1}
\boldsymbol{H}' = \boldsymbol{H} -\Lambda \boldsymbol{E} \preceq 0,
\end{equation}
is negative semi-definite. Here $\boldsymbol{E}$ is the identity matrix. 

Otherwise, the same requirement is imposed on the matrix
\begin{equation}
\label{he2}
\boldsymbol{H}''=
\boldsymbol{H}\left(\boldsymbol{E} - \frac{\mathbf{v}\,\mathbf{v}^T}{\left|\mathbf{v}\right|^2}\right)=
\boldsymbol{H} - \Lambda \frac{\mathbf{v}\,\mathbf{v}^T}{\left|\mathbf{v}\right|^2}
\preceq 0,
\end{equation}
where the expression in parentheses is the projection to the subspace orthogonal to $\mathbf{v}$.

Both inequalities \eqref{he1},\eqref{he2} are efficiently checked by Cholesky decomposition algorithm for arbitrary dimensionality.

In the practically important 2-dimensional case analysis is particularly simple. Note, that zero is an eigenvalue of both $\boldsymbol{H}'$ and $\boldsymbol{H}''$ matrices. The second eigenvalue is equal to the trace of these matrices. It is obvious that
\begin{equation*}
\Tr E = 2, \qquad \Tr \frac{\mathbf{v}\,\mathbf{v}^T}{\left|\mathbf{v}\right|^2} = 1.
\end{equation*}
Inequalities \eqref{he1},\eqref{he2} can therefore be simplified to:
\begin{equation*}
\tag{$5^*$}
\Tr\boldsymbol{H} - 2\Lambda \leq 0,
\end{equation*}
\begin{equation*}
\tag{$6^*$}
\Tr \boldsymbol{H} - \Lambda \leq 0.
\end{equation*}



\begin{thebibliography}{9}
\bibitem{ridges94}
D. Eberly, R. Gardner, B. Morse, S. Pizer, and C. Scharlach,
\textit{Ridges for Image Analysis},
\href{https://doi.org/10.1007/BF01262402}{J Math Imaging Vis \textbf{4}, 353 (1994)}.
\bibitem{ridges96}
D. Eberly,
\textit{Ridges in Image and Data Analysis},
Computational Imaging and Vision \textbf{7} (Springer Netherlands, 1996).
\end{thebibliography}
\end{document}



